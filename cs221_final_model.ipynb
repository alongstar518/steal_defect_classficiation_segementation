{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cs221_final_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alongstar518/cs221_finalproject/blob/master/cs221_final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jrE-XVcM44qr"
      },
      "source": [
        "### CS221 Final Project: Steel Defect Detection \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w-EvsLVbSHCZ"
      },
      "source": [
        "### install packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OC82MEAsSMyt",
        "colab": {}
      },
      "source": [
        "# No for now"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E88AO-Gw44qu"
      },
      "source": [
        "### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "colab_type": "code",
        "id": "goMfOUNL44qv",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm_notebook\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim \n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.utils.data as utils\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import tensorboard\n",
        "from tensorboard import notebook\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xZEX96Lh7xEg"
      },
      "source": [
        "### Print torch and cuda information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o6yTwds977TR",
        "colab": {}
      },
      "source": [
        "print(\"torch version: {}\".format(torch.__version__))\n",
        "print(\"Cuda device avaliablity: {}\".format(torch.cuda.is_available()))\n",
        "print(\"Cuda device name: {}\".format(torch.cuda.get_device_name()))\n",
        "print(\"Cuda device Capilibility: {}\".format(\n",
        "    torch.cuda.get_device_capability(device=None)\n",
        "  )\n",
        ")\n",
        "gpu_ram = (\n",
        "    torch.cuda.get_device_properties(device=None).total_memory / (1024) **3\n",
        ")\n",
        "print(f\"GPU RAM: {gpu_ram} GB\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "602qzAwtTEjx"
      },
      "source": [
        "### configs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C5LQpbyYxsBK"
      },
      "source": [
        "basic config:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DEoG4ebyTG3i",
        "colab": {}
      },
      "source": [
        "reload_data = True\n",
        "clear_tensor_board_history = False\n",
        "reload_last_model = False\n",
        "leave_progress_bar = False\n",
        "inference_mode = False\n",
        "# path to local project folder contains the data\n",
        "path = \"/home/user/git/cs221_finalproject\"\n",
        "data_path = os.path.join(path, \"data\")\n",
        "train_data_percent = 0.8\n",
        "eval_data_percent = 0.1\n",
        "test_data_percent = 0.1 # used only when we don`t have any eval set."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0_XzUBIC5U-s"
      },
      "source": [
        "hyperparamters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bEzjFzXJ5YDb",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "n_classes = 1\n",
        "total_epochs = 10\n",
        "weight_decay=1e-4\n",
        "lr = 0.01\n",
        "momentum=0.9\n",
        "eval_interval = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nNrvGJrZ44qx"
      },
      "source": [
        "### download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YirRY6xP44qx",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # delay import so we can run on local machine\n",
        "  # this also check if run it on google drive or not . if it is not, it will \n",
        "  # avoiding runing from google colab, but running from local.\n",
        "  from google.colab import drive\n",
        "  path = \"/content/drive/My Drive/share/\"\n",
        "  remote_data_path = os.path.join(path, \"data\")\n",
        "  data_path = \"/content/data\"\n",
        "  data_zip_path = os.path.join(\n",
        "        remote_data_path, \"severstal-steel-defect-detection.zip\"\n",
        "      )\n",
        "  model_save_path = path\n",
        "  data_zip_path_dst = \"/content/severstal-steel-defect-detection.zip\"\n",
        "  res18_path = os.path.join(remote_data_path, \"resnet18\")\n",
        "  os.makedirs(data_path, exist_ok=True)\n",
        "  res18_path_dst = os.path.join(data_path, \"resnet18\")\n",
        "  # you may find res18 folder here:\n",
        "  # \"https://drive.google.com/drive/folders/\n",
        "  #  1KFKRraGbNUICgkgSabzrfHeJzYc5YE0W?usp=sharing\"\n",
        "\n",
        "  if reload_data:\n",
        "    print(\"login to google drive\")\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Copy res18 folder:\")\n",
        "    shutil.copytree(res18_path, res18_path_dst)\n",
        "    print(\"Copy raw data from {} to {}\".format(\n",
        "        data_zip_path, data_zip_path_dst)\n",
        "    )\n",
        "    shutil.copy(data_zip_path, \"/content\")\n",
        "\n",
        "    print(\"unzip raw data...\")\n",
        "    os.system(\"unzip {} -d {}\".format(data_zip_path_dst, data_path))\n",
        "    \n",
        "    print(\"give back missing permissions for unzipping\")\n",
        "    os.system(\n",
        "      \"chmod +wrx /content/data/train_images.zip /content/data/test_images.zip\"\n",
        "    )\n",
        "    \n",
        "    print(\"unzipping data...\")\n",
        "    os.system(\"unzip {} -d {}\".format(\n",
        "        os.path.join(data_path,\"train_images.zip\"), \n",
        "        os.path.join(data_path,\"train_images\")\n",
        "        )\n",
        "    )\n",
        "    os.system(\"unzip {} -d {}\".format(\n",
        "        os.path.join(data_path,\"test_images.zip\"), \n",
        "        os.path.join(data_path,\"test_images\")\n",
        "      )\n",
        "    )\n",
        "    !ls /content/data\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  print(\"Running on local machine.\")\n",
        "finally:\n",
        "  model_save_path = os.path.join(path, \"best.pth\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "laZ_V0oy44q2",
        "colab": {}
      },
      "source": [
        "tr = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
        "print(len(tr))\n",
        "tr.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eDJzvU5e44q4",
        "colab": {}
      },
      "source": [
        "df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\n",
        "df_train = df_train[df_train['ImageId_ClassId']\n",
        ".apply(lambda x: x.split('_')[1] == '4')].reset_index(drop=True)\n",
        "print(len(df_train))\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "18qvJkxP44q6"
      },
      "source": [
        "### data preprocessing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o0Q2nyma44q7",
        "colab": {}
      },
      "source": [
        "# Decod\n",
        "def rle2mask(rle, imgshape):\n",
        "    width = imgshape[0]\n",
        "    height= imgshape[1]\n",
        "    \n",
        "    mask= np.zeros( width*height ).astype(np.uint8)\n",
        "    \n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        mask[int(start):int(start+lengths[index])] = 1\n",
        "        current_position += lengths[index]\n",
        "        \n",
        "    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )\n",
        "\n",
        "# Encode\n",
        "def mask2rle(img):\n",
        "    tmp = np.rot90( np.flipud( img ), k=3 )\n",
        "    rle = []\n",
        "    lastColor = 0;\n",
        "    startpos = 0\n",
        "    endpos = 0\n",
        "\n",
        "    tmp = tmp.reshape(-1,1)   \n",
        "    for i in range( len(tmp) ):\n",
        "        if (lastColor==0) and tmp[i]>0:\n",
        "            startpos = i\n",
        "            lastColor = 1\n",
        "        elif (lastColor==1)and(tmp[i]==0):\n",
        "            endpos = i-1\n",
        "            lastColor = 0\n",
        "            rle.append( str(startpos)+' '+str(endpos-startpos+1) )\n",
        "    return \" \".join(rle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aXX07J1x44q8"
      },
      "source": [
        "### Display some sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xxlfGPZ_44q9",
        "colab": {}
      },
      "source": [
        "columns = 1\n",
        "rows = 4\n",
        "fig = plt.figure(figsize=(20,columns*rows+6))\n",
        "for i in range(1,columns*rows+1):\n",
        "    fn = df_train['ImageId_ClassId'].str[:-2].iloc[i]\n",
        "    fig.add_subplot(rows, columns, i).set_title(fn)\n",
        "    img = cv2.imread(data_path + '/train_images/'+fn)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    mask = rle2mask(df_train['EncodedPixels'].iloc[i], (256, 1600))\n",
        "    img[mask==1,0] = 255\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "79LOZzCp44q_"
      },
      "source": [
        "### Create train Dataset argumentation and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7jPfKaHI44q_",
        "colab": {}
      },
      "source": [
        "class ImageData(Dataset):\n",
        "    def __init__(self, df, transform, subset=\"train\"):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.subset = subset\n",
        "        \n",
        "        if self.subset == \"train\":\n",
        "            self.data_path = data_path + '/train_images/'\n",
        "        elif self.subset == \"test\":\n",
        "            self.data_path = data_path + '/test_images/'\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):                      \n",
        "        fn = self.df['ImageId_ClassId'].iloc[index].split('_')[0]         \n",
        "        img = Image.open(self.data_path + fn)\n",
        "        img = self.transform(img)\n",
        "\n",
        "        if self.subset == 'train': \n",
        "            mask = rle2mask(self.df['EncodedPixels'].iloc[index], (256, 1600))\n",
        "            mask = transforms.ToPILImage()(mask)            \n",
        "            mask = self.transform(mask)\n",
        "            return img, mask\n",
        "        else: \n",
        "            mask = None\n",
        "            return img  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WOmNaEtU44rB",
        "colab": {}
      },
      "source": [
        "# Not enable augumentation yet\n",
        "# This will need argument the ground truth.\n",
        "data_transf = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((256, 256)),\n",
        "     transforms.ToTensor()\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_indx = int(len(df_train) * train_data_percent)\n",
        "df_tr = df_train[0: train_indx]\n",
        "\n",
        "eval_indx = int(len(df_train) * eval_data_percent) + train_indx\n",
        "df_eval = df_train[train_indx: eval_indx]\n",
        "\n",
        "df_test = df_train[eval_indx:]\n",
        "\n",
        "train_data = ImageData(df = df_tr, transform = data_transf)\n",
        "train_loader = DataLoader(\n",
        "    dataset = train_data, batch_size=batch_size, shuffle=True\n",
        "  )\n",
        "\n",
        "eval_data = ImageData(df = df_eval, transform = data_transf)\n",
        "eval_loader = DataLoader(dataset = eval_data)\n",
        "\n",
        "test_data = ImageData(df = df_test, transform = data_transf)\n",
        "test_loader = DataLoader(dataset = test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LUGHi1Cg44rD"
      },
      "source": [
        "### Show some image and ground truth (masks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sHHMacAX44rD",
        "colab": {}
      },
      "source": [
        "plt.imshow(train_data[3][0].permute(1, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gjbltWGm44rF",
        "colab": {}
      },
      "source": [
        "plt.imshow(np.squeeze(train_data[3][1].permute(1, 2, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_BrgSSyVOZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(np.squeeze(eval_data[10][1].permute(1,2,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "05aAuTsJ44rH"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Ip3xbJ-yTYM"
      },
      "source": [
        "UNet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fmCEugbZ44rH",
        "colab": {}
      },
      "source": [
        "def convrelu(in_channels, out_channels, kernel, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.base_model = models.resnet18()\n",
        "        self.base_model.load_state_dict(torch.load(os.path.join(data_path, \"resnet18/resnet18.pth\")))\n",
        "        self.base_layers = list(self.base_model.children())\n",
        "\n",
        "        self.layer0 = nn.Sequential(*self.base_layers[:3])\n",
        "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
        "        self.layer1 = nn.Sequential(*self.base_layers[3:5])\n",
        "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
        "        self.layer2 = self.base_layers[5]\n",
        "        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
        "        self.layer3 = self.base_layers[6]\n",
        "        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
        "        self.layer4 = self.base_layers[7]\n",
        "        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
        "\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
        "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
        "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
        "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
        "\n",
        "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
        "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
        "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
        "\n",
        "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x_original = self.conv_original_size0(input)\n",
        "        x_original = self.conv_original_size1(x_original)\n",
        "\n",
        "        layer0 = self.layer0(input)\n",
        "        layer1 = self.layer1(layer0)\n",
        "        layer2 = self.layer2(layer1)\n",
        "        layer3 = self.layer3(layer2)\n",
        "        layer4 = self.layer4(layer3)\n",
        "\n",
        "        layer4 = self.layer4_1x1(layer4)\n",
        "        x = self.upsample(layer4)\n",
        "        layer3 = self.layer3_1x1(layer3)\n",
        "        x = torch.cat([x, layer3], dim=1)\n",
        "        x = self.conv_up3(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer2 = self.layer2_1x1(layer2)\n",
        "        x = torch.cat([x, layer2], dim=1)\n",
        "        x = self.conv_up2(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer1 = self.layer1_1x1(layer1)\n",
        "        x = torch.cat([x, layer1], dim=1)\n",
        "        x = self.conv_up1(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer0 = self.layer0_1x1(layer0)\n",
        "        x = torch.cat([x, layer0], dim=1)\n",
        "        x = self.conv_up0(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, x_original], dim=1)\n",
        "        x = self.conv_original_size2(x)\n",
        "\n",
        "        out = self.conv_last(x)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QTBghQVhyYwn"
      },
      "source": [
        "### Train Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ShbS55vH44rJ",
        "colab": {}
      },
      "source": [
        "model = UNet(n_class=1).cuda()\n",
        "if reload_last_model and os.path.exists(model_save_path):\n",
        "  print(\"Loading model from {}\".format(model_save_path))\n",
        "  model.load_state_dict(torch.load(model_save_path))\n",
        "else:\n",
        "  print(\"Not load model, train from scrath\")\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(), weight_decay=weight_decay, lr = lr, momentum=momentum\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TCb_jX1vnjOr"
      },
      "source": [
        "### training eval and test functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GF_n3mWEirMi"
      },
      "source": [
        "Get LR value if we use lr decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fcFWxz0HnmWs",
        "colab": {}
      },
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dGrxNrusiuyG"
      },
      "source": [
        "Eval Matrics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zzCGiMk8i0ed",
        "colab": {}
      },
      "source": [
        "SMOOTH = 1e-6\n",
        "\n",
        "def dice_coefficient(x, y):\n",
        "  \"\"\"\n",
        "  :param X: numpy array\n",
        "  :param y: numpy array\n",
        "  :return: float, dice coefficient for one x, y pair\n",
        "  x, y is mask the preidiction values (mask)\n",
        "  \"\"\"\n",
        "  x = x.squeeze()\n",
        "  y = y.squeeze()\n",
        "  #print(sum(((x*y) > 0)))\n",
        "  #print(sum((x+y) > 0))\n",
        "  return 2. * ((x == 1) & (y == 1)).sum(1, 2) / (np.sum(x == 1) + np.sum(y == 1)).sum(1, 2)\n",
        "\n",
        "\n",
        "def iou_numpy(outputs: np.array, labels: np.array):\n",
        "    outputs = outputs.squeeze(1)\n",
        "    \n",
        "    intersection = ((outputs == 1) & (labels == 1)).sum((1, 2))\n",
        "    union = ((outputs == 1) | (labels == 1)).sum((1, 2))\n",
        "    \n",
        "    iou = (intersection + SMOOTH) / (union + SMOOTH)\n",
        "    \n",
        "    thresholded = np.ceil(np.clip(20 * (iou - 0.5), 0, 10)) / 10\n",
        "    \n",
        "    return thresholded\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n61_D7-VqTI8"
      },
      "source": [
        "Inference:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9JMFfq4DqWY1",
        "colab": {}
      },
      "source": [
        "def predict(model, data_loader, resize=False, out_mask=True):\n",
        "    predict = []\n",
        "    Y = []\n",
        "    raw = []\n",
        "    model.eval()\n",
        "    print(\"Predicting...\")\n",
        "    total = 0\n",
        "    losses = []\n",
        "    with tqdm_notebook(total=len(data_loader.dataset), leave=leave_progress_bar) as pbar:\n",
        "      for data, y in data_loader:\n",
        "        o = model(data.cuda())  \n",
        "        o = o.cpu().detach().numpy() * (-1)\n",
        "        tmp = np.copy(o)\n",
        "        loss = criterion(torch.tensor(tmp), y)\n",
        "        losses.append(loss)\n",
        "\n",
        "        mn = np.mean(o)*1.2\n",
        "        tmp[tmp < mn] = 0\n",
        "        tmp[tmp > mn] = 1\n",
        "        y_tmp = np.mean(y.numpy())*1.2\n",
        "        y[y < y_tmp] = 0\n",
        "        y[y > y_tmp] = 1\n",
        "\n",
        "        predict.append(tmp)\n",
        "        raw.append(data)\n",
        "        Y.append(y)\n",
        "\n",
        "        pbar.update(1)\n",
        "    predict_loss = np.average(losses)\n",
        "    print(f\"Predict Loss = {predict_loss}\")\n",
        "    return predict, Y, raw, predict_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hhEZZeDoyuc4"
      },
      "source": [
        "Eval Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u-fQt2Fzs741",
        "colab": {}
      },
      "source": [
        "def eval_data_set(model, data_loader, matrics):\n",
        "  corr = []\n",
        "  predictions, Y, raw, loss = predict(model, data_loader)\n",
        "  for i, mask in enumerate(predictions):\n",
        "    corr.append(matrics(mask, Y[i].numpy()))\n",
        "  return np.mean(corr), predictions, Y, raw, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPcWGy0rbRFH",
        "colab_type": "text"
      },
      "source": [
        "Tensorbaord Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1vhrCkuSm6Kf",
        "colab": {}
      },
      "source": [
        "if clear_tensor_board_history:\n",
        "  shutil.rmtree(\"/content/runs\", ignore_errors=True)\n",
        "  os.mkdir(\"/content/runs\")\n",
        "\n",
        "summary_writter = SummaryWriter() # in ./run by default\n",
        "\n",
        "def write_image_to_tb(\n",
        "    predictions, \n",
        "    raw_truth, \n",
        "    raw, \n",
        "    epoch,\n",
        "    category=\"eval\", \n",
        "    update_frequency=10\n",
        "):\n",
        "  images_to_add_raw = []\n",
        "  images_to_add_predict = []\n",
        "  images_to_add_y = []\n",
        "  for i, prediction in enumerate(predictions):\n",
        "      if i // update_frequency == 0:\n",
        "        images_to_add_raw.append(raw[i].squeeze(0))\n",
        "        images_to_add_predict.append(torch.tensor(prediction).squeeze(1))\n",
        "        images_to_add_y.append(raw_truth[i].squeeze(1))\n",
        "\n",
        "  summary_writter.add_image(\n",
        "    f'{epoch}_{category}_raw_img', \n",
        "    torchvision.utils.make_grid(images_to_add_raw, nrow=100), \n",
        "    epoch\n",
        "  )\n",
        "  summary_writter.add_image(\n",
        "    f'{epoch}_{category}_prediction', \n",
        "    torchvision.utils.make_grid(images_to_add_predict, nrow=100), \n",
        "    epoch\n",
        "  )\n",
        "  summary_writter.add_image(\n",
        "      f'{epoch}_{category}_ground_truth', \n",
        "      torchvision.utils.make_grid(images_to_add_y, nrow=100), \n",
        "      epoch\n",
        "  )\n",
        "  summary_writter.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C-X7elt4iiYY"
      },
      "source": [
        "Launch Tensorbaord:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fux464zkVfdw",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CO62PLi344rL"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Qxwzvt844rL",
        "colab": {}
      },
      "source": [
        "if inference_mode: \n",
        "  total_epochs = 0\n",
        "\n",
        "total_it = 0\n",
        "last_result = 0\n",
        "current_it = 1\n",
        "for epoch in range(total_epochs):\n",
        "  print(f\"Epoch: {epoch}\")\n",
        "  model.train()\n",
        "  with tqdm_notebook(total=len(train_loader.dataset), leave=leave_progress_bar) as pbar:   \n",
        "    for it, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        data_len = len(data)\n",
        "        pbar.update(len(data))\n",
        "        pbar.set_postfix(epoch=epoch, loss=loss.item())\n",
        "        total_it += data_len\n",
        "        summary_writter.add_scalar(\"Loss/train\", loss.item(), total_it)\n",
        "        summary_writter.add_scalar(\"LR/train\", get_lr(optimizer), total_it)\n",
        "        summary_writter.flush()\n",
        "    # eval after each epoch\n",
        "    corr, predictions, raw_truth, raw, loss = eval_data_set(\n",
        "          model, eval_loader, iou_numpy\n",
        "        )\n",
        "  write_image_to_tb(predictions, raw_truth, raw, epoch, \"eval\")\n",
        "  print(\"Result = {}\".format(corr))\n",
        "  if corr > last_result:\n",
        "    print(\"Saving Model...\")\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    last_result = corr\n",
        "  summary_writter.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJaKJCzwai-X",
        "colab_type": "text"
      },
      "source": [
        "### Test on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lKK3y0wh0MkZ",
        "colab": {}
      },
      "source": [
        "corr, predictions, raw_truth, raw, loss = eval_data_set(model, test_loader, iou_numpy)\n",
        "print(\"Test set Corr = {}\".format(corr))\n",
        "write_image_to_tb(predictions, raw_truth, raw, 1, \"test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvNq7O8W7Xpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_writter.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}