{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "base.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alongstar518/cs221_finalproject/blob/master/base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrE-XVcM44qr",
        "colab_type": "text"
      },
      "source": [
        "### Steel Defect Detection \n",
        "\n",
        "This is basic kernel to start participating in this competition.\n",
        "It shows how to use PyTorch for solving the segmentation problem.\n",
        "If you prefer to use Keras, I also created others basic Kernels: \n",
        "1. https://www.kaggle.com/ateplyuk/keras-starter-segmentation\n",
        "1. https://www.kaggle.com/ateplyuk/keras-starter-u-net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io9Tr7sE44qt",
        "colab_type": "text"
      },
      "source": [
        "Architecture of Model is U-Net with pretrained encoder. In our case it ResNet18.\n",
        "\n",
        "![](https://github.com/ushur/Severstal-Steel-Defect-Detection/blob/master/unet.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E88AO-Gw44qu",
        "colab_type": "text"
      },
      "source": [
        "### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "goMfOUNL44qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm_notebook\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim \n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.utils.data as utils\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZEX96Lh7xEg",
        "colab_type": "text"
      },
      "source": [
        "### Print some basic information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6yTwds977TR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNrvGJrZ44qx",
        "colab_type": "text"
      },
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YirRY6xP44qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/My Drive/share/cs221data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_XzUBIC5U-s",
        "colab_type": "text"
      },
      "source": [
        "### hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEzjFzXJ5YDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "weight_decay=1e-4 \n",
        "lr = 0.001\n",
        "momentum=0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c3XBSip44q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip \"/content/drive/My Drive/share/severstal-steel-defect-detection.zip\" -d \"/content/drive/My Drive/share/cs221data/\"\n",
        "#!ls -la \"/content/drive/My Drive/share/cs221data\"\n",
        "#!chmod +wrx \"/content/drive/My Drive/share/cs221data/test_images.zip\" \"/content/drive/My Drive/share/cs221data/train_images.zip\"\n",
        "#!unzip \"/content/drive/My Drive/share/cs221data/test_images.zip\" -d \"/content/drive/My Drive/share/cs221data/test_images\"\n",
        "#!unzip \"/content/drive/My Drive/share/cs221data/train_images.zip\" -d \"/content/drive/My Drive/share/cs221data/train_images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laZ_V0oy44q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr = pd.read_csv(os.path.join(path, 'train.csv'))\n",
        "print(len(tr))\n",
        "tr.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv6zu_Ad44q4",
        "colab_type": "text"
      },
      "source": [
        "#### To simplify and speed up process, n this kernel I use only images with ClassId=4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDJzvU5e44q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\n",
        "#df_train = df_train[df_train['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')].reset_index(drop=True)\n",
        "print(len(df_train))\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18qvJkxP44q6",
        "colab_type": "text"
      },
      "source": [
        "### Decode mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Q2nyma44q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rle2mask(rle, imgshape):\n",
        "    width = imgshape[0]\n",
        "    height= imgshape[1]\n",
        "    \n",
        "    mask= np.zeros( width*height ).astype(np.uint8)\n",
        "    \n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        mask[int(start):int(start+lengths[index])] = 1\n",
        "        current_position += lengths[index]\n",
        "        \n",
        "    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXX07J1x44q8",
        "colab_type": "text"
      },
      "source": [
        "### Display some images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxlfGPZ_44q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = 1\n",
        "rows = 4\n",
        "fig = plt.figure(figsize=(20,columns*rows+6))\n",
        "for i in range(1,columns*rows+1):\n",
        "    fn = df_train['ImageId_ClassId'].str[:-2].iloc[i]\n",
        "    fig.add_subplot(rows, columns, i).set_title(fn)\n",
        "    img = cv2.imread( path + 'train_images/'+fn )\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    mask = rle2mask(df_train['EncodedPixels'].iloc[i], (256, 1600))\n",
        "    img[mask==1,0] = 255\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79LOZzCp44q_",
        "colab_type": "text"
      },
      "source": [
        "### Create train Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jPfKaHI44q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageData(Dataset):\n",
        "    def __init__(self, df, transform, subset=\"train\"):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.subset = subset\n",
        "        \n",
        "        if self.subset == \"train\":\n",
        "            self.data_path = path + 'train_images/'\n",
        "        elif self.subset == \"test\":\n",
        "            self.data_path = path + 'test_images/'\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):                      \n",
        "        fn = self.df['ImageId_ClassId'].iloc[index].split('_')[0]         \n",
        "        img = Image.open(self.data_path + fn)\n",
        "        img = self.transform(img)\n",
        "\n",
        "        if self.subset == 'train': \n",
        "            mask = rle2mask(self.df['EncodedPixels'].iloc[index], (256, 1600))\n",
        "            mask = transforms.ToPILImage()(mask)            \n",
        "            mask = self.transform(mask)\n",
        "            return img, mask\n",
        "        else: \n",
        "            mask = None\n",
        "            return img       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOmNaEtU44rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transf = transforms.Compose([\n",
        "                                  transforms.Resize((256, 256)),\n",
        "                                  transforms.ToTensor()])\n",
        "train_data = ImageData(df = df_train, transform = data_transf)\n",
        "train_loader = DataLoader(dataset = train_data, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUGHi1Cg44rD",
        "colab_type": "text"
      },
      "source": [
        "### Show some image and mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHHMacAX44rD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(train_data[3][0].permute(1, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjbltWGm44rF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(np.squeeze(train_data[3][1].permute(1, 2, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05aAuTsJ44rH",
        "colab_type": "text"
      },
      "source": [
        "### Create U-Net Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmCEugbZ44rH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convrelu(in_channels, out_channels, kernel, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.base_model = models.resnet18()\n",
        "        self.base_model.load_state_dict(torch.load(os.path.join(\n",
        "            path, \"resnet18/resnet18.pth\"))\n",
        "        )\n",
        "        self.base_layers = list(self.base_model.children())\n",
        "\n",
        "        self.layer0 = nn.Sequential(*self.base_layers[:3])\n",
        "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
        "        self.layer1 = nn.Sequential(*self.base_layers[3:5])\n",
        "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
        "        self.layer2 = self.base_layers[5]\n",
        "        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
        "        self.layer3 = self.base_layers[6]\n",
        "        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
        "        self.layer4 = self.base_layers[7]\n",
        "        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
        "\n",
        "        self.upsample = nn.Upsample(\n",
        "            scale_factor=2, mode='bilinear', align_corners=True\n",
        "            )\n",
        "\n",
        "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
        "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
        "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
        "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
        "\n",
        "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
        "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
        "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
        "\n",
        "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x_original = self.conv_original_size0(input)\n",
        "        x_original = self.conv_original_size1(x_original)\n",
        "\n",
        "        layer0 = self.layer0(input)\n",
        "        layer1 = self.layer1(layer0)\n",
        "        layer2 = self.layer2(layer1)\n",
        "        layer3 = self.layer3(layer2)\n",
        "        layer4 = self.layer4(layer3)\n",
        "\n",
        "        layer4 = self.layer4_1x1(layer4)\n",
        "        x = self.upsample(layer4)\n",
        "        layer3 = self.layer3_1x1(layer3)\n",
        "        x = torch.cat([x, layer3], dim=1)\n",
        "        x = self.conv_up3(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer2 = self.layer2_1x1(layer2)\n",
        "        x = torch.cat([x, layer2], dim=1)\n",
        "        x = self.conv_up2(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer1 = self.layer1_1x1(layer1)\n",
        "        x = torch.cat([x, layer1], dim=1)\n",
        "        x = self.conv_up1(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer0 = self.layer0_1x1(layer0)\n",
        "        x = torch.cat([x, layer0], dim=1)\n",
        "        x = self.conv_up0(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, x_original], dim=1)\n",
        "        x = self.conv_original_size2(x)\n",
        "\n",
        "        out = self.conv_last(x)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShbS55vH44rJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = UNet(n_class=1).cuda()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(), weight_decay=weight_decay, lr = lr, momentum=momentum\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO62PLi344rL",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qxwzvt844rL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(5):      \n",
        "    model.train()\n",
        "    with tqdm_notebook(total=len(train_loader.dataset)) as pbar:         \n",
        "      for ii, (data, target) in enumerate(train_loader):                         \n",
        "          data, target = data.cuda(), target.cuda()\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          pbar.update(len(data))\n",
        "          pbar.set_postfix(epoch=epoch, loss=loss.item())          \n",
        "    print('Epoch: {} - Loss: {:.6f}'.format(epoch + 1, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRfUPVnG44rN",
        "colab_type": "text"
      },
      "source": [
        "### Show prediction on image from train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT37cKhy44rO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(train_data[6][0].permute(1, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GuiQlC544rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = train_data[6][0].unsqueeze(0)\n",
        "o = model(x.cuda())  \n",
        "o = o.cpu().detach().numpy() * (-1)\n",
        "tmp = np.copy(o)\n",
        "mn = np.mean(o)*1.2\n",
        "tmp[tmp<mn] = 0\n",
        "tmp[tmp>mn] = 1\n",
        "plt.imshow(np.squeeze(tmp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UK4rUQ844rX",
        "colab_type": "text"
      },
      "source": [
        "### Read submit file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-Wb2Q5O44rY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit = pd.read_csv(path + 'sample_submission.csv', converters={'EncodedPixels': lambda e: ' '})\n",
        "print(len(submit))\n",
        "sub4 = submit[submit['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')]\n",
        "print(len(sub4))\n",
        "sub4.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79-bZgng44rb",
        "colab_type": "text"
      },
      "source": [
        "### Create test Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js_s4qsm44rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = ImageData(df = sub4, transform = data_transf, subset=\"test\")\n",
        "test_loader = DataLoader(dataset = test_data, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtrMQr5Y44re",
        "colab_type": "text"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-b_GqvR44rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "predict = []\n",
        "model.eval()\n",
        "for data in test_loader:\n",
        "    data = data.cuda()\n",
        "    output = model(data)  \n",
        "    output = output.cpu().detach().numpy() * (-1)    \n",
        "    predict.append(abs(output[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhNMm49B44rg",
        "colab_type": "text"
      },
      "source": [
        "### Encode mask "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwTtID2044rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask2rle(img):\n",
        "    tmp = np.rot90( np.flipud( img ), k=3 )\n",
        "    rle = []\n",
        "    lastColor = 0;\n",
        "    startpos = 0\n",
        "    endpos = 0\n",
        "\n",
        "    tmp = tmp.reshape(-1,1)   \n",
        "    for i in range( len(tmp) ):\n",
        "        if (lastColor==0) and tmp[i]>0:\n",
        "            startpos = i\n",
        "            lastColor = 1\n",
        "        elif (lastColor==1)and(tmp[i]==0):\n",
        "            endpos = i-1\n",
        "            lastColor = 0\n",
        "            rle.append( str(startpos)+' '+str(endpos-startpos+1) )\n",
        "    return \" \".join(rle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISgDOgA844rk",
        "colab_type": "text"
      },
      "source": [
        "### Resize images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoYhtHBY44rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "pred_rle = []\n",
        "  \n",
        "for p in predict:        \n",
        "    img = np.copy(p)\n",
        "    mn = np.mean(img)*1.2\n",
        "    img[img<=mn] = 0\n",
        "    img[img>mn] = 1\n",
        "    img = cv2.resize(img[0], (1600, 256))\n",
        "    \n",
        "    pred_rle.append(mask2rle(img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UPmucpx44rm",
        "colab_type": "text"
      },
      "source": [
        "### Prepare submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87Cy2KwT44rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit['EncodedPixels'][submit['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')] = pred_rle\n",
        "submit.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQIu_O9-44ro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_s = cv2.imread( path + 'test_images/'+ submit['ImageId_ClassId'][47].split('_')[0])\n",
        "plt.imshow(img_s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNvKvkvY44rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_s = rle2mask(submit['EncodedPixels'][47], (256, 1600))\n",
        "plt.imshow(mask_s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v1Yv9bk44rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNiuIVI244rt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}