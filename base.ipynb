{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "base.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alongstar518/cs221_finalproject/blob/master/base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrE-XVcM44qr",
        "colab_type": "text"
      },
      "source": [
        "### Steel Defect Detection \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io9Tr7sE44qt",
        "colab_type": "text"
      },
      "source": [
        "Architecture of Model is U-Net with pretrained encoder. In our case it ResNet18.\n",
        "\n",
        "![](https://github.com/ushur/Severstal-Steel-Defect-Detection/blob/master/unet.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E88AO-Gw44qu",
        "colab_type": "text"
      },
      "source": [
        "### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "goMfOUNL44qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm_notebook\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim \n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.utils.data as utils\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZEX96Lh7xEg",
        "colab_type": "text"
      },
      "source": [
        "### Print some basic information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6yTwds977TR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "02f3ab37-b699-4192-e92a-5a6be1fcbfc0"
      },
      "source": [
        "print(torch.__version__)\n",
        "print(\"Cuda device avaliablity: {}\".format(torch.cuda.is_available()))\n",
        "print(\"Cuda device name: {}\".format(torch.cuda.get_device_name()))\n",
        "print(\"Cuda device Capilibility: {}\".format(\n",
        "    torch.cuda.get_device_capability(device=None)\n",
        "  )\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.3.0+cu100\n",
            "Cuda device avaliablity: True\n",
            "Cuda device name: Tesla K80\n",
            "Cuda device Capilibility: (3, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "602qzAwtTEjx",
        "colab_type": "text"
      },
      "source": [
        "### basic config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEoG4ebyTG3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reload_data = True\n",
        "path = \"your local path here if you do not run on colab\"\n",
        "data_path = \"/content/drive/My Drive/share\" # path to data on google drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNrvGJrZ44qx",
        "colab_type": "text"
      },
      "source": [
        "### download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YirRY6xP44qx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5d9537cf-7a9b-4923-9ed1-9de561540a1b"
      },
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  data_zip_path = os.path.join(data_path, \"severstal-steel-defect-detection.zip\")\n",
        "  data_zip_path_dst = \"/content/severstal-steel-defect-detection.zip\"\n",
        "  path = os.path.join(\"/content/data\")\n",
        "\n",
        "  if reload_data:\n",
        "    print(\"Copy raw data from {} to {}\".format(data_zip_path, data_zip_path_dst))\n",
        "    shutil.copy(data_zip_path, \"/content\")\n",
        "\n",
        "    print(\"unzip raw data...\")\n",
        "    os.system(\"unzip {} -d {}\".format(data_zip_path_dst, path))\n",
        "    \n",
        "    print(\"give back missing permissions for unzipping\")\n",
        "    os.system(\n",
        "      \"chmod +wrx /content/data/train_images.zip /content/data/test_images.zip\"\n",
        "    )\n",
        "    \n",
        "    print(\"unzipping data...\")\n",
        "    os.system(\"unzip {} -d {}\".format(\n",
        "        os.path.join(path,\"train_images.zip\"), \n",
        "        os.path.join(path,\"train_images\")\n",
        "        )\n",
        "    )\n",
        "    os.system(\"unzip {} -d {}\".format(\n",
        "        os.path.join(path,\"test_images.zip\"), \n",
        "        os.path.join(path,\"test_images\")\n",
        "      )\n",
        "    )\n",
        "    on_colab = True\n",
        "except:\n",
        "  on_colab = False\n",
        "\n",
        "!ls /content/data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Copy raw data from /content/drive/My Drive/share/severstal-steel-defect-detection.zip to /content/severstal-steel-defect-detection.zip\n",
            "unzip raw data...\n",
            "give back missing permissions for unzipping\n",
            "unzipping data...\n",
            "sample_submission.csv  test_images.zip\ttrain_images\n",
            "test_images\t       train.csv\ttrain_images.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_XzUBIC5U-s",
        "colab_type": "text"
      },
      "source": [
        "### hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEzjFzXJ5YDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "weight_decay=1e-4 \n",
        "lr = 0.001\n",
        "momentum=0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c3XBSip44q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip \"/content/drive/My Drive/share/severstal-steel-defect-detection.zip\" -d \"/content/drive/My Drive/share/cs221data/\"\n",
        "#!ls -la \"/content/drive/My Drive/share/cs221data\"\n",
        "#!chmod +wrx \"/content/drive/My Drive/share/cs221data/test_images.zip\" \"/content/drive/My Drive/share/cs221data/train_images.zip\"\n",
        "#!unzip \"/content/drive/My Drive/share/cs221data/test_images.zip\" -d \"/content/drive/My Drive/share/cs221data/test_images\"\n",
        "#!unzip \"/content/drive/My Drive/share/cs221data/train_images.zip\" -d \"/content/drive/My Drive/share/cs221data/train_images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laZ_V0oy44q2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b3f20663-f219-41b5-893b-06846e1a32f4"
      },
      "source": [
        "tr = pd.read_csv(os.path.join(path, 'train.csv'))\n",
        "print(len(tr))\n",
        "tr.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId_ClassId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002cc93b.jpg_1</td>\n",
              "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002cc93b.jpg_2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0002cc93b.jpg_3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0002cc93b.jpg_4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00031f466.jpg_1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ImageId_ClassId                                      EncodedPixels\n",
              "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
              "1  0002cc93b.jpg_2                                                NaN\n",
              "2  0002cc93b.jpg_3                                                NaN\n",
              "3  0002cc93b.jpg_4                                                NaN\n",
              "4  00031f466.jpg_1                                                NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv6zu_Ad44q4",
        "colab_type": "text"
      },
      "source": [
        "#### To simplify and speed up process, n this kernel I use only images with ClassId=4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDJzvU5e44q4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b8945f50-db19-475f-da00-c000f7e6348f"
      },
      "source": [
        "df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\n",
        "print(len(df_train))\n",
        "df_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId_ClassId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002cc93b.jpg_1</td>\n",
              "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0007a71bf.jpg_3</td>\n",
              "      <td>18661 28 18863 82 19091 110 19347 110 19603 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000a4bcdd.jpg_1</td>\n",
              "      <td>37607 3 37858 8 38108 14 38359 20 38610 25 388...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000f6bf48.jpg_4</td>\n",
              "      <td>131973 1 132228 4 132483 6 132738 8 132993 11 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0014fce06.jpg_3</td>\n",
              "      <td>229501 11 229741 33 229981 55 230221 77 230468...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ImageId_ClassId                                      EncodedPixels\n",
              "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
              "1  0007a71bf.jpg_3  18661 28 18863 82 19091 110 19347 110 19603 11...\n",
              "2  000a4bcdd.jpg_1  37607 3 37858 8 38108 14 38359 20 38610 25 388...\n",
              "3  000f6bf48.jpg_4  131973 1 132228 4 132483 6 132738 8 132993 11 ...\n",
              "4  0014fce06.jpg_3  229501 11 229741 33 229981 55 230221 77 230468..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18qvJkxP44q6",
        "colab_type": "text"
      },
      "source": [
        "### Decode mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Q2nyma44q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rle2mask(rle, imgshape):\n",
        "    width = imgshape[0]\n",
        "    height= imgshape[1]\n",
        "    \n",
        "    mask= np.zeros( width*height ).astype(np.uint8)\n",
        "    \n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        mask[int(start):int(start+lengths[index])] = 1\n",
        "        current_position += lengths[index]\n",
        "        \n",
        "    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXX07J1x44q8",
        "colab_type": "text"
      },
      "source": [
        "### Display some images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxlfGPZ_44q9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "4fa90393-aaf2-4761-9efc-ec4cce01fcdb"
      },
      "source": [
        "columns = 1\n",
        "rows = 4\n",
        "fig = plt.figure(figsize=(20,columns*rows+6))\n",
        "for i in range(1,columns*rows+1):\n",
        "    fn = df_train['ImageId_ClassId'].str[:-2].iloc[i]\n",
        "    fig.add_subplot(rows, columns, i).set_title(fn)\n",
        "    img = cv2.imread( path + 'train_images/'+fn )\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    mask = rle2mask(df_train['EncodedPixels'].iloc[i], (256, 1600))\n",
        "    img[mask==1,0] = 255\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-77dca9b63a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train_images/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrle2mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EncodedPixels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(3.4.3) /io/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIkAAAClCAYAAADYk60GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79LOZzCp44q_",
        "colab_type": "text"
      },
      "source": [
        "### Create train Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jPfKaHI44q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageData(Dataset):\n",
        "    def __init__(self, df, transform, subset=\"train\"):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.subset = subset\n",
        "        \n",
        "        if self.subset == \"train\":\n",
        "            self.data_path = path + 'train_images/'\n",
        "        elif self.subset == \"test\":\n",
        "            self.data_path = path + 'test_images/'\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):                      \n",
        "        fn = self.df['ImageId_ClassId'].iloc[index].split('_')[0]         \n",
        "        img = Image.open(self.data_path + fn)\n",
        "        img = self.transform(img)\n",
        "\n",
        "        if self.subset == 'train': \n",
        "            mask = rle2mask(self.df['EncodedPixels'].iloc[index], (256, 1600))\n",
        "            mask = transforms.ToPILImage()(mask)            \n",
        "            mask = self.transform(mask)\n",
        "            return img, mask\n",
        "        else: \n",
        "            mask = None\n",
        "            return img       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOmNaEtU44rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transf = transforms.Compose([\n",
        "                                  transforms.Resize((256, 256)),\n",
        "                                  transforms.ToTensor()])\n",
        "train_data = ImageData(df = df_train, transform = data_transf)\n",
        "train_loader = DataLoader(dataset = train_data, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUGHi1Cg44rD",
        "colab_type": "text"
      },
      "source": [
        "### Show some image and mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHHMacAX44rD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(train_data[3][0].permute(1, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjbltWGm44rF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(np.squeeze(train_data[3][1].permute(1, 2, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05aAuTsJ44rH",
        "colab_type": "text"
      },
      "source": [
        "### Create U-Net Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmCEugbZ44rH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convrelu(in_channels, out_channels, kernel, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.base_model = models.resnet18()\n",
        "        self.base_model.load_state_dict(torch.load(os.path.join(\n",
        "            path, \"resnet18/resnet18.pth\"))\n",
        "        )\n",
        "        self.base_layers = list(self.base_model.children())\n",
        "\n",
        "        self.layer0 = nn.Sequential(*self.base_layers[:3])\n",
        "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
        "        self.layer1 = nn.Sequential(*self.base_layers[3:5])\n",
        "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
        "        self.layer2 = self.base_layers[5]\n",
        "        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
        "        self.layer3 = self.base_layers[6]\n",
        "        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
        "        self.layer4 = self.base_layers[7]\n",
        "        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
        "\n",
        "        self.upsample = nn.Upsample(\n",
        "            scale_factor=2, mode='bilinear', align_corners=True\n",
        "            )\n",
        "\n",
        "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
        "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
        "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
        "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
        "\n",
        "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
        "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
        "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
        "\n",
        "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x_original = self.conv_original_size0(input)\n",
        "        x_original = self.conv_original_size1(x_original)\n",
        "\n",
        "        layer0 = self.layer0(input)\n",
        "        layer1 = self.layer1(layer0)\n",
        "        layer2 = self.layer2(layer1)\n",
        "        layer3 = self.layer3(layer2)\n",
        "        layer4 = self.layer4(layer3)\n",
        "\n",
        "        layer4 = self.layer4_1x1(layer4)\n",
        "        x = self.upsample(layer4)\n",
        "        layer3 = self.layer3_1x1(layer3)\n",
        "        x = torch.cat([x, layer3], dim=1)\n",
        "        x = self.conv_up3(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer2 = self.layer2_1x1(layer2)\n",
        "        x = torch.cat([x, layer2], dim=1)\n",
        "        x = self.conv_up2(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer1 = self.layer1_1x1(layer1)\n",
        "        x = torch.cat([x, layer1], dim=1)\n",
        "        x = self.conv_up1(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        layer0 = self.layer0_1x1(layer0)\n",
        "        x = torch.cat([x, layer0], dim=1)\n",
        "        x = self.conv_up0(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, x_original], dim=1)\n",
        "        x = self.conv_original_size2(x)\n",
        "\n",
        "        out = self.conv_last(x)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShbS55vH44rJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = UNet(n_class=1).cuda()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(), weight_decay=weight_decay, lr = lr, momentum=momentum\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO62PLi344rL",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qxwzvt844rL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(5):      \n",
        "    model.train()\n",
        "    with tqdm_notebook(total=len(train_loader.dataset)) as pbar:         \n",
        "      for ii, (data, target) in enumerate(train_loader):                         \n",
        "          data, target = data.cuda(), target.cuda()\n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          pbar.update(len(data))\n",
        "          pbar.set_postfix(epoch=epoch, loss=loss.item())          \n",
        "    print('Epoch summary: {} - Loss: {:.6f}'.format(epoch + 1, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRfUPVnG44rN",
        "colab_type": "text"
      },
      "source": [
        "### Show prediction on image from train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT37cKhy44rO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(train_data[6][0].permute(1, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GuiQlC544rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = train_data[6][0].unsqueeze(0)\n",
        "o = model(x.cuda())  \n",
        "o = o.cpu().detach().numpy() * (-1)\n",
        "tmp = np.copy(o)\n",
        "mn = np.mean(o)*1.2\n",
        "tmp[tmp<mn] = 0\n",
        "tmp[tmp>mn] = 1\n",
        "plt.imshow(np.squeeze(tmp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UK4rUQ844rX",
        "colab_type": "text"
      },
      "source": [
        "### Read submit file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-Wb2Q5O44rY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit = pd.read_csv(path + 'sample_submission.csv', converters={'EncodedPixels': lambda e: ' '})\n",
        "print(len(submit))\n",
        "sub4 = submit[submit['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')]\n",
        "print(len(sub4))\n",
        "sub4.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79-bZgng44rb",
        "colab_type": "text"
      },
      "source": [
        "### Create test Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js_s4qsm44rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = ImageData(df = sub4, transform = data_transf, subset=\"test\")\n",
        "test_loader = DataLoader(dataset = test_data, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtrMQr5Y44re",
        "colab_type": "text"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-b_GqvR44rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "predict = []\n",
        "model.eval()\n",
        "for data in test_loader:\n",
        "    data = data.cuda()\n",
        "    output = model(data)  \n",
        "    output = output.cpu().detach().numpy() * (-1)    \n",
        "    predict.append(abs(output[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhNMm49B44rg",
        "colab_type": "text"
      },
      "source": [
        "### Encode mask "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwTtID2044rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask2rle(img):\n",
        "    tmp = np.rot90( np.flipud( img ), k=3 )\n",
        "    rle = []\n",
        "    lastColor = 0;\n",
        "    startpos = 0\n",
        "    endpos = 0\n",
        "\n",
        "    tmp = tmp.reshape(-1,1)   \n",
        "    for i in range( len(tmp) ):\n",
        "        if (lastColor==0) and tmp[i]>0:\n",
        "            startpos = i\n",
        "            lastColor = 1\n",
        "        elif (lastColor==1)and(tmp[i]==0):\n",
        "            endpos = i-1\n",
        "            lastColor = 0\n",
        "            rle.append( str(startpos)+' '+str(endpos-startpos+1) )\n",
        "    return \" \".join(rle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISgDOgA844rk",
        "colab_type": "text"
      },
      "source": [
        "### Resize images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoYhtHBY44rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "pred_rle = []\n",
        "  \n",
        "for p in predict:        \n",
        "    img = np.copy(p)\n",
        "    mn = np.mean(img)*1.2\n",
        "    img[img<=mn] = 0\n",
        "    img[img>mn] = 1\n",
        "    img = cv2.resize(img[0], (1600, 256))\n",
        "    \n",
        "    pred_rle.append(mask2rle(img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UPmucpx44rm",
        "colab_type": "text"
      },
      "source": [
        "### Prepare submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87Cy2KwT44rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit['EncodedPixels'][submit['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')] = pred_rle\n",
        "submit.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQIu_O9-44ro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_s = cv2.imread( path + 'test_images/'+ submit['ImageId_ClassId'][47].split('_')[0])\n",
        "plt.imshow(img_s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNvKvkvY44rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_s = rle2mask(submit['EncodedPixels'][47], (256, 1600))\n",
        "plt.imshow(mask_s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v1Yv9bk44rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNiuIVI244rt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}